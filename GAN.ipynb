{"cells":[{"metadata":{"id":"ycnl7remE4Da","outputId":"d299eae7-c2a1-4476-fd52-b097a0b8d8d8","trusted":false},"cell_type":"code","source":"from google.colab import drive\ndrive.mount('./content')","execution_count":null,"outputs":[]},{"metadata":{"id":"VMuiQPG2EAmO","outputId":"c022083e-8f3c-405f-adb2-3e28c2020851","trusted":true},"cell_type":"code","source":"import keras\nkeras.__version__","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"'2.4.3'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"- 생성자"},{"metadata":{"id":"7tDdMra6HLx1","outputId":"b00729e0-fa30-4b93-84e1-935fd9703ffa","trusted":true},"cell_type":"code","source":"from keras import layers\nimport numpy as np\n\nlatent_dim = 32\nheight = 32\nwidth = 32\nchannels = 3\n\ngenerator_input = keras.Input(shape=(latent_dim,))\n\n# 입력을 16 × 16 크기의 128개 채널을 가진 특성 맵으로 변환합니다\nx = layers.Dense(128 * 16 * 16)(generator_input)\nx = layers.LeakyReLU()(x)\nx = layers.Reshape((16, 16, 128))(x)\n\n# 합성곱 층을 추가합니다\nx = layers.Conv2D(256, 5, padding='same')(x)\nx = layers.LeakyReLU()(x)\n\n# 32 × 32 크기로 업샘플링합니다\nx = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\nx = layers.LeakyReLU()(x)\n\n# 합성곱 층을 더 추가합니다\nx = layers.Conv2D(256, 5, padding='same')(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(256, 5, padding='same')(x)\nx = layers.LeakyReLU()(x)\n\n# 32 × 32 크기의 1개 채널을 가진 특성 맵을 생성합니다\nx = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\ngenerator = keras.models.Model(generator_input, x)\ngenerator.summary()","execution_count":2,"outputs":[{"output_type":"stream","text":"Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 32)]              0         \n_________________________________________________________________\ndense (Dense)                (None, 32768)             1081344   \n_________________________________________________________________\nleaky_re_lu (LeakyReLU)      (None, 32768)             0         \n_________________________________________________________________\nreshape (Reshape)            (None, 16, 16, 128)       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 16, 16, 256)       819456    \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 256)       0         \n_________________________________________________________________\nconv2d_transpose (Conv2DTran (None, 32, 32, 256)       1048832   \n_________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 32, 32, 256)       1638656   \n_________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n_________________________________________________________________\nleaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 32, 32, 3)         37635     \n=================================================================\nTotal params: 6,264,579\nTrainable params: 6,264,579\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"- 판별자\n    - : 후보이미지(진짜 또는 가짜)를 입력으로 받고 2개의 클래스로 분류\n    - 클래스는 '생성된 이미지' 또는 '훈련세트에서 온 진짜 이미지' 이다.\n"},{"metadata":{"id":"kGXJ0sRsDon1","outputId":"0ee9ce08-106b-4082-ae95-51e6ad5732a5","trusted":true},"cell_type":"code","source":"discriminator_input = layers.Input(shape=(height, width, channels))\nx = layers.Conv2D(128, 3)(discriminator_input)\nx = layers.LeakyReLU()(x)\nx = layers.Dropout(0.3)(x)       # droput 4개 추가\nx = layers.Conv2D(128, 4, strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Dropout(0.3)(x)\nx = layers.Conv2D(128, 4, strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Dropout(0.3)(x)\nx = layers.Conv2D(128, 4, strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Dropout(0.3)(x)\nx = layers.Flatten()(x)\n\n# 드롭아웃 층을 넣는 것이 아주 중요합니다!\nx = layers.Dropout(0.4)(x)\n\n# 분류 층\nx = layers.Dense(1, activation='sigmoid')(x)\n\n# (32,32, 3) 크기의 입력을 이진분류 결정(진짜/가짜)로 변환하는 판별자 모델 객체 생성\ndiscriminator = keras.models.Model(discriminator_input, x)\ndiscriminator.summary()\n\n\ndiscriminator_optimizer = keras.optimizers.RMSprop(lr=0.00008  # 학습률 낮춤\n                                                   , clipvalue=1.0 # 옵티마이저에서 (값을 지정하여) 그래디언트 클리핑을 사용 \n                                                   , decay=1e-8)   # 안정된 훈련을 위해서 학습률 감쇠를 사용합니다\ndiscriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')","execution_count":25,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"__init__() missing 1 required positional argument: 'rate'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-5f7d0364d8cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# inplace = True로 설정하면이 작업을 제자리에서 수행합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'rate'"]}]},{"metadata":{},"cell_type":"markdown","source":"- 적대적 네트워크\n    - 생성자와 판별자를 연결하여 GAN을 설정\n    - 훈련 시, 생성자가 판별자를 속이는 방향으로 학습\n    - 이 모델은 잠재 공간의 포인트를 \"진짜\" 또는 \"가짜\"의 분류 결정으로 변환\n    - 훈련에 사용되는 타깃 레이블은 항상 \"진짜 이미지\"이다.\n    - 훈련하는 동안 판별자를 동결하는 것이 중요. (학습되지 않도록. 가중치가 업데이트되지 않도록)\n\n\n- : GAN을 훈련하는 것은 DISCRIMINATOR가 가짜 이미지를 보고 진짜라고 예측하도록 만들기 위해 GENERATOR의 가중치를 업데이트.\n\n"},{"metadata":{"id":"vdnJURzJDold","trusted":true},"cell_type":"code","source":"# 판별자의 가중치가 훈련되지 않도록 설정합니다(gan 모델에만 적용됩니다)\ndiscriminator.trainable = False\n\ngan_input = keras.Input(shape=(latent_dim,))\ngan_output = discriminator(generator(gan_input))\ngan = keras.models.Model(gan_input, gan_output)\n\ngan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\ngan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 데이터 로드"},{"metadata":{"id":"-sbORRhaD3qA","trusted":true},"cell_type":"code","source":"import os\nfrom keras.preprocessing import image","execution_count":5,"outputs":[]},{"metadata":{"id":"s6vKNkE3FR8A","trusted":true},"cell_type":"code","source":"img_dir = \"../input/convert-image\"\n\n# img_dir = '/content/content/MyDrive/Colab Notebooks/sai/10img.zip (Unzipped Files)'","execution_count":13,"outputs":[]},{"metadata":{"id":"9HwMMRXXGR5t","trusted":true},"cell_type":"code","source":"from PIL import Image\nfrom numpy import asarray\nx_train = []","execution_count":8,"outputs":[]},{"metadata":{"id":"tL11J74fGU5a","trusted":true},"cell_type":"code","source":"for i in os.listdir(img_dir):\n  # load the image\n  image = Image.open(os.path.join(img_dir, i))\n  # convert image to numpy array\n  data = asarray(image)\n  x_train.append(data)\n\nx_train= asarray(x_train)\nx_train = x_train/255.    #정규화","execution_count":14,"outputs":[]},{"metadata":{"id":"lhmVI7N1HIc4","trusted":true},"cell_type":"code","source":"x_train= asarray(x_train)","execution_count":15,"outputs":[]},{"metadata":{"id":"a8kBut5VHOSB","outputId":"5728c174-4ebd-493f-92c5-72c64ffe55a8","trusted":true},"cell_type":"code","source":"x_train.shape # (504개의 이미지, 32, 32, 3채널)","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"(504, 32, 32, 3)"},"metadata":{}}]},{"metadata":{"id":"P2CF9EQND6wh","trusted":true},"cell_type":"code","source":"# 데이터를 정규화합니다\nx_train = x_train.reshape(\n    (x_train.shape[0],) + (height, width, channels)).astype('float32') / 255.","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- GAN 훈련 구현\n\n\n- 훈련시, 적대적 손실이 크게 증가한다면(= 판별자의 손실은 0으로 향하는 경우), 판별자의 학습률을 낮추고 판별자의 드롭아웃 비율을 높이기"},{"metadata":{"id":"i9SmubdhDohC","outputId":"8fe7d9a0-5db8-46bf-c47a-6f5675d387b3","trusted":true},"cell_type":"code","source":"iterations = 100\nbatch_size = 64\n\n# 생성된 이미지 저장 위치 지정\nsave_dir = './gan_images/'\nif not os.path.exists(save_dir):\n    os.mkdir(save_dir)\n\n# 훈련 반복 시작\nstart = 0\nfor step in range(iterations):\n    # 잠재 공간에서 무작위로 포인트를 샘플링합니다\n    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n\n    # 가짜 이미지를 디코딩합니다\n    generated_images = generator.predict(random_latent_vectors)\n\n    # 진짜 이미지와 연결합니다\n    stop = start + batch_size\n    real_images = x_train[start: stop]\n    combined_images = np.concatenate([generated_images, real_images]) \n\n    # 진짜와 가짜 이미지를 구분하여 레이블을 합칩니다\n    # generate 1, real 0\n    labels = np.concatenate([np.ones((batch_size, 1)),\n                             np.zeros((batch_size, 1))])\n    # 레이블에 랜덤 노이즈를 추가합니다. 아주 중요합니다!\n    labels += 0.05 * np.random.random(labels.shape)\n\n    # discriminator를 훈련합니다\n    d_loss = discriminator.train_on_batch(combined_images, labels)\n\n    # 잠재 공간에서 무작위로 포인트를 샘플링합니다\n    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n\n    # 모두 “진짜 이미지\"라고 레이블을 만듭니다 (사실은 거짓)\n    misleading_targets = np.zeros((batch_size, 1))\n\n    # generator를 훈련합니다(gan 모델에서 discriminator의 가중치는 동결됩니다)\n    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n    \n    start += batch_size\n    if start > len(x_train) - batch_size:\n      start = 0\n\n    # 중간 중간 저장하고 그래프를 그립니다 (100번 스텝마다)\n    if step % 10 == 0:\n        # 모델 가중치를 저장합니다\n        gan.save_weights('gan.h5')\n\n        # 측정 지표를 출력합니다\n        print('스텝 %s에서 판별자 손실: %s' % (step, d_loss))\n        print('스텝 %s에서 적대적 손실: %s' % (step, a_loss))\n\n        # 생성된 이미지 하나를 저장합니다\n        # img = image.array_to_img(generated_images[0] * 255., scale=False)\n        # img = generated_images[0] * 255.\n        img = Image.fromarray(generated_images[0] * 255., 'RGB')\n        img.save(os.path.join(save_dir, 'generated_img' + str(step) + '.png'))\n\n        # 비교를 위해 진짜 이미지 하나를 저장합니다\n        # img = image.array_to_img(real_images[0] * 255., scale=False)\n        # img = real_images[0] * 255.\n        img = Image.fromarray(real_images[0] * 255., 'RGB')\n        img.save(os.path.join(save_dir, 'real_img' + str(step) + '.png'))","execution_count":18,"outputs":[{"output_type":"stream","text":"스텝 0에서 판별자 손실: 0.6932320594787598\n스텝 0에서 적대적 손실: 0.7532095313072205\n스텝 10에서 판별자 손실: 0.5282623171806335\n스텝 10에서 적대적 손실: 2.428219795227051\n스텝 20에서 판별자 손실: 0.6990195512771606\n스텝 20에서 적대적 손실: 0.7936890125274658\n스텝 30에서 판별자 손실: 0.697198212146759\n스텝 30에서 적대적 손실: 0.7597161531448364\n스텝 40에서 판별자 손실: 0.6946892738342285\n스텝 40에서 적대적 손실: 0.7197667360305786\n스텝 50에서 판별자 손실: 0.4044938087463379\n스텝 50에서 적대적 손실: 4.474719047546387\n스텝 60에서 판별자 손실: 0.23664575815200806\n스텝 60에서 적대적 손실: 7.416868209838867\n스텝 70에서 판별자 손실: 0.11404924094676971\n스텝 70에서 적대적 손실: 28.40412712097168\n스텝 80에서 판별자 손실: 0.25061625242233276\n스텝 80에서 적대적 손실: 2.069443702697754\n스텝 90에서 판별자 손실: 0.5029643177986145\n스텝 90에서 적대적 손실: 11.750680923461914\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nimport time\n\niterations = 1000\nbatch_size = 64\nsave_dir = './gan_images/'\nif not os.path.exists(save_dir):\n    os.mkdir(save_dir)\n\n# 훈련 반복 시작\nstart = 0\nfor step in range(iterations):\n    s = time.time()\n    # 잠재 공간에서 무작위로 포인트를 샘플링합니다\n    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n\n    # 가짜 이미지를 디코딩합니다\n    generated_images = generator.predict(random_latent_vectors)\n\n    # 진짜 이미지와 연결합니다\n    stop = start + batch_size\n    real_images = x_train[start: stop]\n    combined_images = np.concatenate([generated_images, real_images])\n\n    # 진짜와 가짜 이미지를 구분하여 레이블을 합칩니다\n    labels = np.concatenate([np.ones((batch_size, 1)),\n                             np.zeros((batch_size, 1))])\n    # 레이블에 랜덤 노이즈를 추가합니다. 아주 중요합니다!\n    labels += 0.05 * np.random.random(labels.shape)\n\n    # discriminator를 훈련합니다\n    d_loss = discriminator.train_on_batch(combined_images, labels)\n\n    # 잠재 공간에서 무작위로 포인트를 샘플링합니다\n    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n\n    # 모두 “진짜 이미지\"라고 레이블을 만듭니다\n    misleading_targets = np.zeros((batch_size, 1))\n\n    # generator를 훈련합니다(gan 모델에서 discriminator의 가중치는 동결됩니다)\n    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n    \n    start += batch_size\n    if start > len(x_train) - batch_size:\n      start = 0\n\n    # 중간 중간 저장하고 그래프를 그립니다\n    if step % 100 == 0:\n        # 모델 가중치를 저장합니다\n        gan.save_weights('gan.h5')\n\n        # 측정 지표를 출력합니다\n        print('스텝 %s에서 판별자 손실: %s' % (step, d_loss))\n        print('스텝 %s에서 적대적 손실: %s' % (step, a_loss))\n\n        # 생성된 이미지 하나를 저장합니다\n        # img = image.array_to_img(generated_images[0] * 255., scale=False)\n        # img = generated_images[0] * 255.\n        img = Image.fromarray(generated_images[0] * 255., 'RGB')\n        img.save(os.path.join(save_dir, 'generated_img' + str(step) + '.png'))\n\n        # 비교를 위해 진짜 이미지 하나를 저장합니다\n        # img = image.array_to_img(real_images[0] * 255., scale=False)\n        # img = real_images[0] * 255.\n        img = Image.fromarray(real_images[0] * 255., 'RGB')\n        img.save(os.path.join(save_dir, 'real_img' + str(step) + '.png'))\n    e = time.time()\n    print('%d번째 소요시간: ' %step ,end='')\n    print(e-s)\n\n'''","execution_count":null,"outputs":[]},{"metadata":{"id":"wrKyEwJzDoe_","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":20,"outputs":[]},{"metadata":{"id":"hqRibm9aDvLz","trusted":true},"cell_type":"code","source":"# 잠재 공간에서 랜덤한 포인트를 샘플링합니다\nrandom_latent_vectors = np.random.normal(size=(10, latent_dim))\n\n# 가짜 이미지로 디코딩합니다\ngenerated_images = generator.predict(random_latent_vectors)\n\nfor i in range(generated_images.shape[0]):\n    img = image.array_to_img(generated_images[i] * 255., scale=False)\n    plt.figure()\n    plt.imshow(img)\n    \nplt.show()","execution_count":21,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'JpegImageFile' object has no attribute 'array_to_img'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-8db26811ef64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'JpegImageFile' object has no attribute 'array_to_img'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}