{"cells":[{"metadata":{"id":"ycnl7remE4Da","outputId":"d299eae7-c2a1-4476-fd52-b097a0b8d8d8","trusted":false},"cell_type":"code","source":"from google.colab import drive\ndrive.mount('./content')","execution_count":null,"outputs":[]},{"metadata":{"id":"VMuiQPG2EAmO","outputId":"c022083e-8f3c-405f-adb2-3e28c2020851","trusted":true},"cell_type":"code","source":"import keras\nkeras.__version__","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"'2.4.3'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"- 생성자"},{"metadata":{"id":"7tDdMra6HLx1","outputId":"b00729e0-fa30-4b93-84e1-935fd9703ffa","trusted":true},"cell_type":"code","source":"from keras import layers\nimport numpy as np\n\nlatent_dim = 32\nheight = 32\nwidth = 32\nchannels = 3\n\ngenerator_input = keras.Input(shape=(latent_dim,))\n\n# 입력을 16 × 16 크기의 128개 채널을 가진 특성 맵으로 변환합니다\nx = layers.Dense(128 * 16 * 16)(generator_input)\nx = layers.BatchNormalization()(x)      # BN추가 5개\nx = layers.LeakyReLU()(x)\nx = layers.Reshape((16, 16, 128))(x)\n\n# 합성곱 층을 추가합니다\nx = layers.Conv2DTranspose(256, 5, padding='same')(x)  # Conv2D\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU()(x)\n\n# 32 × 32 크기로 업샘플링합니다\nx = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU()(x)\n\n# 합성곱 층을 더 추가합니다\nx = layers.Conv2D(256, 5, padding='same')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(256, 5, padding='same')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU()(x)\n\n# 32 × 32 크기의 1개 채널을 가진 특성 맵을 생성합니다\nx = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\ngenerator = keras.models.Model(generator_input, x)\ngenerator.summary()","execution_count":30,"outputs":[{"output_type":"stream","text":"Model: \"functional_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_4 (InputLayer)         [(None, 32)]              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 32768)             1081344   \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 32768)             131072    \n_________________________________________________________________\nleaky_re_lu_9 (LeakyReLU)    (None, 32768)             0         \n_________________________________________________________________\nreshape_1 (Reshape)          (None, 16, 16, 128)       0         \n_________________________________________________________________\nconv2d_transpose_1 (Conv2DTr (None, 16, 16, 256)       819456    \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 16, 16, 256)       1024      \n_________________________________________________________________\nleaky_re_lu_10 (LeakyReLU)   (None, 16, 16, 256)       0         \n_________________________________________________________________\nconv2d_transpose_2 (Conv2DTr (None, 32, 32, 256)       1048832   \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 32, 32, 256)       1024      \n_________________________________________________________________\nleaky_re_lu_11 (LeakyReLU)   (None, 32, 32, 256)       0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 32, 32, 256)       1638656   \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 32, 32, 256)       1024      \n_________________________________________________________________\nleaky_re_lu_12 (LeakyReLU)   (None, 32, 32, 256)       0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 32, 32, 256)       1638656   \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 32, 32, 256)       1024      \n_________________________________________________________________\nleaky_re_lu_13 (LeakyReLU)   (None, 32, 32, 256)       0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 32, 32, 3)         37635     \n=================================================================\nTotal params: 6,399,747\nTrainable params: 6,332,163\nNon-trainable params: 67,584\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"- 판별자\n    - : 후보이미지(진짜 또는 가짜)를 입력으로 받고 2개의 클래스로 분류\n    - 클래스는 '생성된 이미지' 또는 '훈련세트에서 온 진짜 이미지' 이다.\n"},{"metadata":{"id":"kGXJ0sRsDon1","outputId":"0ee9ce08-106b-4082-ae95-51e6ad5732a5","trusted":true},"cell_type":"code","source":"discriminator_input = layers.Input(shape=(height, width, channels))\nx = layers.Conv2D(128, 3)(discriminator_input)\nx = layers.LeakyReLU()(x)\nx = layers.Dropout(0.5)(x)       # droput 4개 추가\nx = layers.Conv2D(128, 4, strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Dropout(0.5)(x)\nx = layers.Conv2D(128, 4, strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Dropout(0.5)(x)\nx = layers.Conv2D(128, 4, strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Dropout(0.5)(x)\nx = layers.Flatten()(x)\n\n# 드롭아웃 층을 넣는 것이 아주 중요합니다!\nx = layers.Dropout(0.4)(x)\n\n# 분류 층\nx = layers.Dense(1, activation='sigmoid')(x)\n\n# (32,32, 3) 크기의 입력을 이진분류 결정(진짜/가짜)로 변환하는 판별자 모델 객체 생성\ndiscriminator = keras.models.Model(discriminator_input, x)\ndiscriminator.summary()\n\n\ndiscriminator_optimizer = keras.optimizers.RMSprop(lr=0.000008  # 학습률 낮춤\n                                                   , clipvalue=1.0 # 옵티마이저에서 (값을 지정하여) 그래디언트 클리핑을 사용 \n                                                   , decay=1e-8)   # 안정된 훈련을 위해서 학습률 감쇠를 사용합니다\ndiscriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')","execution_count":41,"outputs":[{"output_type":"stream","text":"Model: \"functional_13\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_7 (InputLayer)         [(None, 32, 32, 3)]       0         \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 30, 30, 128)       3584      \n_________________________________________________________________\nleaky_re_lu_18 (LeakyReLU)   (None, 30, 30, 128)       0         \n_________________________________________________________________\ndropout_10 (Dropout)         (None, 30, 30, 128)       0         \n_________________________________________________________________\nconv2d_16 (Conv2D)           (None, 14, 14, 128)       262272    \n_________________________________________________________________\nleaky_re_lu_19 (LeakyReLU)   (None, 14, 14, 128)       0         \n_________________________________________________________________\ndropout_11 (Dropout)         (None, 14, 14, 128)       0         \n_________________________________________________________________\nconv2d_17 (Conv2D)           (None, 6, 6, 128)         262272    \n_________________________________________________________________\nleaky_re_lu_20 (LeakyReLU)   (None, 6, 6, 128)         0         \n_________________________________________________________________\ndropout_12 (Dropout)         (None, 6, 6, 128)         0         \n_________________________________________________________________\nconv2d_18 (Conv2D)           (None, 2, 2, 128)         262272    \n_________________________________________________________________\nleaky_re_lu_21 (LeakyReLU)   (None, 2, 2, 128)         0         \n_________________________________________________________________\ndropout_13 (Dropout)         (None, 2, 2, 128)         0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 512)               0         \n_________________________________________________________________\ndropout_14 (Dropout)         (None, 512)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 1)                 513       \n=================================================================\nTotal params: 790,913\nTrainable params: 790,913\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"- 적대적 네트워크\n    - 생성자와 판별자를 연결하여 GAN을 설정\n    - 훈련 시, 생성자가 판별자를 속이는 방향으로 학습\n    - 이 모델은 잠재 공간의 포인트를 \"진짜\" 또는 \"가짜\"의 분류 결정으로 변환\n    - 훈련에 사용되는 타깃 레이블은 항상 \"진짜 이미지\"이다.\n    - 훈련하는 동안 판별자를 동결하는 것이 중요. (학습되지 않도록. 가중치가 업데이트되지 않도록)\n\n\n- : GAN을 훈련하는 것은 DISCRIMINATOR가 가짜 이미지를 보고 진짜라고 예측하도록 만들기 위해 GENERATOR의 가중치를 업데이트.\n\n"},{"metadata":{"id":"vdnJURzJDold","trusted":true},"cell_type":"code","source":"# 판별자의 가중치가 훈련되지 않도록 설정합니다(gan 모델에만 적용됩니다)\ndiscriminator.trainable = False\n\ngan_input = keras.Input(shape=(latent_dim,))\ngan_output = discriminator(generator(gan_input))\ngan = keras.models.Model(gan_input, gan_output)\n\ngan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\ngan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')","execution_count":42,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 데이터 로드"},{"metadata":{"id":"-sbORRhaD3qA","trusted":true},"cell_type":"code","source":"import os\nfrom keras.preprocessing import image","execution_count":43,"outputs":[]},{"metadata":{"id":"s6vKNkE3FR8A","trusted":true},"cell_type":"code","source":"img_dir = \"../input/convert-img\"\n\n# img_dir = '/content/content/MyDrive/Colab Notebooks/sai/10img.zip (Unzipped Files)'","execution_count":44,"outputs":[]},{"metadata":{"id":"9HwMMRXXGR5t","trusted":true},"cell_type":"code","source":"from PIL import Image\nfrom numpy import asarray\n\n","execution_count":45,"outputs":[]},{"metadata":{"id":"tL11J74fGU5a","trusted":true},"cell_type":"code","source":"x_train = []\n\n\nfor i in os.listdir(img_dir):\n  # load the image\n  image = Image.open(os.path.join(img_dir, i))\n  # convert image to numpy array\n  data = asarray(image)\n  x_train.append(data)\n\nx_train= asarray(x_train)\nx_train = x_train/255.    #정규화","execution_count":46,"outputs":[]},{"metadata":{"id":"lhmVI7N1HIc4","trusted":true},"cell_type":"code","source":"x_train= asarray(x_train)","execution_count":47,"outputs":[]},{"metadata":{"id":"a8kBut5VHOSB","outputId":"5728c174-4ebd-493f-92c5-72c64ffe55a8","trusted":true},"cell_type":"code","source":"x_train.shape # (504개의 이미지, 32, 32, 3채널)","execution_count":48,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"(504, 32, 32, 3)"},"metadata":{}}]},{"metadata":{"id":"P2CF9EQND6wh","trusted":true},"cell_type":"code","source":"# 데이터를 정규화합니다\nx_train = x_train.reshape(\n    (x_train.shape[0],) + (height, width, channels)).astype('float32') / 255.","execution_count":49,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- GAN 훈련 구현\n\n\n- 훈련시, 적대적 손실이 크게 증가한다면(= 판별자의 손실은 0으로 향하는 경우), 판별자의 학습률을 낮추고 판별자의 드롭아웃 비율을 높이기"},{"metadata":{"id":"i9SmubdhDohC","outputId":"8fe7d9a0-5db8-46bf-c47a-6f5675d387b3","trusted":true},"cell_type":"code","source":"iterations = 100\nbatch_size = 64\n\n# 생성된 이미지 저장 위치 지정\nsave_dir = './gan_images-2/'\nif not os.path.exists(save_dir):\n    os.mkdir(save_dir)\n\n# 훈련 반복 시작\nstart = 0\nfor step in range(iterations):\n    # 잠재 공간에서 무작위로 포인트를 샘플링합니다\n    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n\n    # 가짜 이미지를 디코딩합니다\n    generated_images = generator.predict(random_latent_vectors)\n\n    # 진짜 이미지와 연결합니다\n    stop = start + batch_size\n    real_images = x_train[start: stop]\n    combined_images = np.concatenate([generated_images, real_images]) \n\n    # 진짜와 가짜 이미지를 구분하여 레이블을 합칩니다\n    # generate 1, real 0\n    labels = np.concatenate([np.ones((batch_size, 1)),\n                             np.zeros((batch_size, 1))])\n    # 레이블에 랜덤 노이즈를 추가합니다. 아주 중요합니다!\n    labels += 0.05 * np.random.random(labels.shape)\n\n    # discriminator를 훈련합니다\n    d_loss = discriminator.train_on_batch(combined_images, labels)\n\n    # 잠재 공간에서 무작위로 포인트를 샘플링합니다\n    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n\n    # 모두 “진짜 이미지\"라고 레이블을 만듭니다 (사실은 거짓)\n    misleading_targets = np.zeros((batch_size, 1))\n\n    # generator를 훈련합니다(gan 모델에서 discriminator의 가중치는 동결됩니다)\n    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n    \n    start += batch_size\n    if start > len(x_train) - batch_size:\n      start = 0\n\n    # 중간 중간 저장하고 그래프를 그립니다 (100번 스텝마다)\n    if step % 10 == 0:\n        # 모델 가중치를 저장합니다\n        gan.save_weights('gan.h5')\n\n        # 측정 지표를 출력합니다\n        print('스텝 %s에서 판별자 손실: %s' % (step, d_loss))\n        print('스텝 %s에서 적대적 손실: %s' % (step, a_loss))\n\n        # 생성된 이미지 하나를 저장합니다\n        # img = image.array_to_img(generated_images[0] * 255., scale=False)\n        # img = generated_images[0] * 255.\n        img = Image.fromarray(generated_images[0] * 255., 'RGB')\n        img.save(os.path.join(save_dir, 'generated_img' + str(step) + '.png'))\n\n        # 비교를 위해 진짜 이미지 하나를 저장합니다\n        # img = image.array_to_img(real_images[0] * 255., scale=False)\n        # img = real_images[0] * 255.\n        img = Image.fromarray(real_images[0] * 255., 'RGB')\n        img.save(os.path.join(save_dir, 'real_img' + str(step) + '.png'))\n        \n        \n# real과 generated 이미지가 각각 10개씩 저장됌. gan_images 폴더에. ","execution_count":50,"outputs":[{"output_type":"stream","text":"스텝 0에서 판별자 손실: 0.6955441832542419\n스텝 0에서 적대적 손실: 0.7043163776397705\n스텝 10에서 판별자 손실: 0.6394461393356323\n스텝 10에서 적대적 손실: 0.7396118640899658\n스텝 20에서 판별자 손실: 0.6723966002464294\n스텝 20에서 적대적 손실: 0.7357919216156006\n스텝 30에서 판별자 손실: 0.6127578020095825\n스텝 30에서 적대적 손실: 0.7272346019744873\n스텝 40에서 판별자 손실: 0.6448622941970825\n스텝 40에서 적대적 손실: 0.7391330599784851\n스텝 50에서 판별자 손실: 0.6658486127853394\n스텝 50에서 적대적 손실: 0.7557953596115112\n스텝 60에서 판별자 손실: 0.6492408514022827\n스텝 60에서 적대적 손실: 0.7559599876403809\n스텝 70에서 판별자 손실: 0.6843950748443604\n스텝 70에서 적대적 손실: 0.7567429542541504\n스텝 80에서 판별자 손실: 0.6766461133956909\n스텝 80에서 적대적 손실: 0.7347612380981445\n스텝 90에서 판별자 손실: 0.6757476329803467\n스텝 90에서 적대적 손실: 0.7545153498649597\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nimport time\n\niterations = 1000\nbatch_size = 64\nsave_dir = './gan_images/'\nif not os.path.exists(save_dir):\n    os.mkdir(save_dir)\n\n# 훈련 반복 시작\nstart = 0\nfor step in range(iterations):\n    s = time.time()\n    # 잠재 공간에서 무작위로 포인트를 샘플링합니다\n    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n\n    # 가짜 이미지를 디코딩합니다\n    generated_images = generator.predict(random_latent_vectors)\n\n    # 진짜 이미지와 연결합니다\n    stop = start + batch_size\n    real_images = x_train[start: stop]\n    combined_images = np.concatenate([generated_images, real_images])\n\n    # 진짜와 가짜 이미지를 구분하여 레이블을 합칩니다\n    labels = np.concatenate([np.ones((batch_size, 1)),\n                             np.zeros((batch_size, 1))])\n    # 레이블에 랜덤 노이즈를 추가합니다. 아주 중요합니다!\n    labels += 0.05 * np.random.random(labels.shape)\n\n    # discriminator를 훈련합니다\n    d_loss = discriminator.train_on_batch(combined_images, labels)\n\n    # 잠재 공간에서 무작위로 포인트를 샘플링합니다\n    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n\n    # 모두 “진짜 이미지\"라고 레이블을 만듭니다\n    misleading_targets = np.zeros((batch_size, 1))\n\n    # generator를 훈련합니다(gan 모델에서 discriminator의 가중치는 동결됩니다)\n    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n    \n    start += batch_size\n    if start > len(x_train) - batch_size:\n      start = 0\n\n    # 중간 중간 저장하고 그래프를 그립니다\n    if step % 100 == 0:\n        # 모델 가중치를 저장합니다\n        gan.save_weights('gan.h5')\n\n        # 측정 지표를 출력합니다\n        print('스텝 %s에서 판별자 손실: %s' % (step, d_loss))\n        print('스텝 %s에서 적대적 손실: %s' % (step, a_loss))\n\n        # 생성된 이미지 하나를 저장합니다\n        # img = image.array_to_img(generated_images[0] * 255., scale=False)\n        # img = generated_images[0] * 255.\n        img = Image.fromarray(generated_images[0] * 255., 'RGB')\n        img.save(os.path.join(save_dir, 'generated_img' + str(step) + '.png'))\n\n        # 비교를 위해 진짜 이미지 하나를 저장합니다\n        # img = image.array_to_img(real_images[0] * 255., scale=False)\n        # img = real_images[0] * 255.\n        img = Image.fromarray(real_images[0] * 255., 'RGB')\n        img.save(os.path.join(save_dir, 'real_img' + str(step) + '.png'))\n    e = time.time()\n    print('%d번째 소요시간: ' %step ,end='')\n    print(e-s)\n\n'''","execution_count":null,"outputs":[]},{"metadata":{"id":"wrKyEwJzDoe_","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":13,"outputs":[]},{"metadata":{"id":"hqRibm9aDvLz","trusted":true},"cell_type":"code","source":"# 잠재 공간에서 랜덤한 포인트를 샘플링합니다\nrandom_latent_vectors = np.random.normal(size=(10, latent_dim))\n\n# 가짜 이미지로 디코딩합니다\ngenerated_images = generator.predict(random_latent_vectors)\ngenerated_images\n\n\n","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"array([[[[ 1.08919904e-01, -8.65708962e-02,  8.51807371e-02],\n         [ 7.32825845e-02, -5.11350073e-02,  1.06641263e-01],\n         [ 1.11892708e-01,  4.52628173e-03, -8.44608154e-03],\n         ...,\n         [-2.00575590e-03, -4.33255136e-02,  4.63296659e-02],\n         [ 1.15833348e-02,  1.85447698e-03, -2.97548473e-02],\n         [-2.92662457e-02, -3.08919756e-04, -3.97513099e-02]],\n\n        [[-2.74372771e-02, -1.27698168e-01,  6.04342632e-02],\n         [ 1.40196294e-01, -4.39131446e-03,  6.82982802e-02],\n         [ 5.15903831e-02,  7.16285631e-02,  1.96350124e-02],\n         ...,\n         [-2.55922731e-02, -2.68872492e-02, -2.72063427e-02],\n         [-3.84704359e-02,  1.82997510e-02, -6.56344891e-02],\n         [-3.97326499e-02,  2.20478866e-02, -9.21749696e-02]],\n\n        [[ 6.10084161e-02, -1.37171715e-01,  1.39644369e-01],\n         [-5.45327552e-04, -1.04225524e-01,  1.46072343e-01],\n         [-2.86261179e-02,  3.54590304e-02, -3.55748273e-02],\n         ...,\n         [-1.33655041e-01, -4.49470915e-02,  6.52281567e-02],\n         [-1.24806449e-01,  4.58340496e-02, -2.69074365e-02],\n         [-1.26867712e-01,  2.10660473e-02, -2.49110796e-02]],\n\n        ...,\n\n        [[-4.87409942e-02, -3.12866718e-01, -3.87517945e-03],\n         [ 1.33407593e-01, -5.07012196e-02, -7.89913908e-03],\n         [ 2.23564357e-01, -1.15864044e-02,  1.29353300e-01],\n         ...,\n         [ 9.98167157e-01, -1.00000000e+00, -9.99560773e-01],\n         [ 9.99997199e-01, -9.99998331e-01,  6.78403258e-01],\n         [ 9.99935091e-01, -9.99998212e-01,  9.85090956e-02]],\n\n        [[ 2.57486459e-02, -1.62119363e-02,  1.13805979e-01],\n         [ 8.93561319e-02, -1.10016696e-01,  1.29559472e-01],\n         [-1.74406469e-01,  1.80291459e-01, -5.71889058e-02],\n         ...,\n         [-3.82178515e-01,  9.97062981e-01, -2.75615484e-01],\n         [-7.12691724e-01,  8.95840585e-01, -9.57860708e-01],\n         [-8.93500686e-01,  9.84023035e-01,  9.63842213e-01]],\n\n        [[-1.28204832e-02, -4.12730724e-02, -4.49005924e-02],\n         [-7.20460527e-03,  1.45676464e-01,  7.41712749e-02],\n         [ 1.73392028e-01,  2.55330354e-01,  3.60967107e-02],\n         ...,\n         [ 9.99908030e-01,  9.64136243e-01, -9.33633626e-01],\n         [ 9.99996960e-01,  8.58072102e-01, -2.46440426e-01],\n         [ 9.99986410e-01, -6.86398029e-01,  2.54467785e-01]]],\n\n\n       [[[ 1.14857949e-01, -8.79696384e-02,  8.74238610e-02],\n         [ 7.73191750e-02, -5.55047356e-02,  1.05133444e-01],\n         [ 1.07634500e-01,  5.22769289e-03, -2.45027873e-03],\n         ...,\n         [-7.32472679e-03, -5.38046397e-02,  5.70385940e-02],\n         [ 1.79460607e-02,  1.68328546e-02, -3.14229950e-02],\n         [-3.08855753e-02, -4.58556181e-03, -3.01578287e-02]],\n\n        [[-3.08942888e-02, -1.29146993e-01,  5.85339814e-02],\n         [ 1.45573527e-01, -5.31137502e-03,  6.74107522e-02],\n         [ 5.51125482e-02,  7.62609914e-02,  1.84157826e-02],\n         ...,\n         [-2.53311135e-02, -3.14561427e-02, -3.65387239e-02],\n         [-3.89563330e-02,  2.88205873e-02, -6.29725754e-02],\n         [-3.79574820e-02,  1.79943200e-02, -8.73138532e-02]],\n\n        [[ 6.33291751e-02, -1.37873963e-01,  1.41823918e-01],\n         [ 3.68047226e-03, -1.12445176e-01,  1.39245570e-01],\n         [-4.43079732e-02,  3.69788222e-02, -2.29178704e-02],\n         ...,\n         [-1.34903535e-01, -7.58737475e-02,  8.95800218e-02],\n         [-1.23558491e-01,  6.05134182e-02, -4.55594994e-02],\n         [-1.29028082e-01,  4.93162917e-03, -2.23646220e-03]],\n\n        ...,\n\n        [[-3.87552492e-02, -2.84253448e-01,  1.08380122e-02],\n         [ 1.24630876e-01, -4.53533009e-02,  1.06626959e-03],\n         [ 1.99627489e-01, -1.05142761e-02,  1.24335200e-01],\n         ...,\n         [-5.75145520e-02, -8.81265551e-02, -2.12149546e-01],\n         [ 6.32670820e-02,  4.99984361e-02,  6.82489648e-02],\n         [ 1.63198691e-02, -4.73959669e-02, -8.75765160e-02]],\n\n        [[ 1.91226080e-02, -2.99248155e-02,  1.10934503e-01],\n         [ 7.58682191e-02, -1.05315752e-01,  1.21194042e-01],\n         [-1.38586476e-01,  1.39207304e-01, -4.42262776e-02],\n         ...,\n         [ 1.25502303e-01, -3.40261101e-03,  1.15769610e-01],\n         [-1.38004839e-01,  5.72427735e-02, -1.02193192e-01],\n         [ 4.90812883e-02,  1.27250180e-01,  3.40594836e-02]],\n\n        [[-1.64447576e-02, -4.29729708e-02, -2.83991229e-02],\n         [ 3.36796511e-03,  1.18024290e-01,  7.97746256e-02],\n         [ 1.38414741e-01,  2.08082080e-01,  5.14419749e-02],\n         ...,\n         [-1.18807107e-01,  8.34487975e-02,  3.77973542e-02],\n         [ 2.16104481e-02,  2.83988655e-01,  8.68455973e-03],\n         [ 3.72179877e-03,  6.56907558e-02,  7.90822282e-02]]],\n\n\n       [[[ 1.06050961e-01, -8.52819383e-02,  8.77004117e-02],\n         [ 7.29949027e-02, -4.88598235e-02,  1.07264318e-01],\n         [ 1.07695401e-01,  2.45631346e-03,  8.66957416e-04],\n         ...,\n         [-1.27174729e-03, -4.92659844e-02,  4.62328456e-02],\n         [ 1.35516133e-02,  6.02548337e-03, -3.10566947e-02],\n         [-3.13429125e-02, -1.73050351e-03, -3.72535549e-02]],\n\n        [[-2.62030419e-02, -1.26542613e-01,  6.26463220e-02],\n         [ 1.39765054e-01, -1.35313254e-03,  7.16135055e-02],\n         [ 4.14742418e-02,  5.91756999e-02,  2.22064145e-02],\n         ...,\n         [-2.47471910e-02, -3.50603536e-02, -3.81254107e-02],\n         [-3.54073271e-02,  2.02389285e-02, -6.26194626e-02],\n         [-3.73182893e-02,  1.99168045e-02, -9.59849283e-02]],\n\n        [[ 5.62150106e-02, -1.29628167e-01,  1.45689979e-01],\n         [-2.32939818e-03, -9.46362093e-02,  1.49060398e-01],\n         [-2.99468264e-02,  4.00621146e-02, -1.26113109e-02],\n         ...,\n         [-1.30545720e-01, -5.79105541e-02,  6.57604709e-02],\n         [-1.29475981e-01,  4.81679589e-02, -3.84048894e-02],\n         [-1.30825341e-01,  1.69360843e-02, -1.70082301e-02]],\n\n        ...,\n\n        [[-5.58151267e-02, -3.43226731e-01,  2.11400483e-02],\n         [ 1.63114175e-01, -1.21377818e-01, -4.30565402e-02],\n         [ 1.89469054e-01, -1.07056111e-01,  1.43374994e-01],\n         ...,\n         [-4.42322306e-02, -8.38953629e-02, -1.53973073e-01],\n         [ 3.67879346e-02,  1.42084118e-02,  5.03134206e-02],\n         [-2.32890416e-02, -1.14603676e-02, -9.12359282e-02]],\n\n        [[ 1.24319838e-02, -1.09116081e-02,  1.01283081e-01],\n         [ 7.77153447e-02, -1.13844015e-01,  7.63883963e-02],\n         [-1.65678605e-01,  2.00560778e-01, -7.02813789e-02],\n         ...,\n         [ 1.34296133e-03, -4.35522385e-03,  6.89962283e-02],\n         [-1.23391010e-01,  5.49579300e-02, -6.81302920e-02],\n         [-1.98557731e-02,  9.18846577e-02,  2.40701698e-02]],\n\n        [[-1.28852259e-02, -2.53960621e-02, -4.31610532e-02],\n         [ 1.95903592e-02,  1.48121938e-01,  8.12853128e-02],\n         [ 1.68236241e-01,  2.61484921e-01,  3.68863754e-02],\n         ...,\n         [-7.98490047e-02,  6.02432191e-02,  3.10002714e-02],\n         [ 1.00525115e-02,  1.71001971e-01,  3.38760391e-02],\n         [-2.77895331e-02,  7.26101622e-02,  4.50946428e-02]]],\n\n\n       ...,\n\n\n       [[[ 1.12029754e-01, -8.75339285e-02,  8.47219154e-02],\n         [ 7.60498047e-02, -5.30465990e-02,  1.05203114e-01],\n         [ 1.12441063e-01,  4.61689383e-03, -9.26893856e-03],\n         ...,\n         [-1.46623133e-02, -5.70652150e-02,  5.90241663e-02],\n         [ 2.61257533e-02,  2.06874982e-02, -3.77788767e-02],\n         [-3.47622633e-02, -7.00242817e-03, -2.81904005e-02]],\n\n        [[-2.76300516e-02, -1.27038866e-01,  5.74676096e-02],\n         [ 1.40606865e-01, -4.76759532e-03,  6.76324293e-02],\n         [ 5.39175980e-02,  7.49096274e-02,  1.91484001e-02],\n         ...,\n         [-2.53529288e-02, -3.96210067e-02, -3.21590006e-02],\n         [-2.55034994e-02,  3.00395321e-02, -6.48302883e-02],\n         [-3.59622203e-02,  1.71633177e-02, -8.58319551e-02]],\n\n        [[ 5.96473478e-02, -1.39627978e-01,  1.39772326e-01],\n         [ 3.59923579e-03, -1.08801052e-01,  1.43561497e-01],\n         [-3.40719223e-02,  3.29112038e-02, -3.18618342e-02],\n         ...,\n         [-1.44171610e-01, -8.96035582e-02,  9.31512937e-02],\n         [-1.11122750e-01,  7.10311905e-02, -4.33073826e-02],\n         [-1.33867905e-01,  1.44778087e-03,  3.18016205e-03]],\n\n        ...,\n\n        [[-2.87565291e-02, -2.75994390e-01,  3.37606482e-02],\n         [ 1.02133684e-01, -1.82391703e-02,  2.71339137e-02],\n         [ 2.09807605e-01,  6.43691570e-02,  1.67991459e-01],\n         ...,\n         [ 2.47867584e-01, -9.33579862e-01, -6.31245971e-01],\n         [ 5.32402337e-01, -8.76964748e-01,  3.57115984e-01],\n         [ 3.89989257e-01, -8.09871078e-01, -1.46359533e-01]],\n\n        [[ 2.56133731e-02, -4.82043959e-02,  1.06775574e-01],\n         [ 1.02478698e-01, -1.17475227e-01,  1.24572054e-01],\n         [-1.55290619e-01,  1.17569998e-01, -4.52771373e-02],\n         ...,\n         [ 6.69603795e-02,  3.66574466e-01,  1.75995946e-01],\n         [-1.56613126e-01,  3.72688770e-01, -2.52178103e-01],\n         [-8.25843364e-02,  4.59628254e-01,  5.37788987e-01]],\n\n        [[-1.30140884e-02, -6.03267141e-02, -8.28809477e-03],\n         [-1.16262669e-02,  1.10221393e-01,  9.44658071e-02],\n         [ 1.34461597e-01,  2.08172783e-01,  9.15993825e-02],\n         ...,\n         [ 5.03982782e-01,  3.17900568e-01, -5.06396964e-02],\n         [ 7.13175476e-01,  3.64589125e-01,  4.46238276e-03],\n         [ 6.68212950e-01, -3.01108733e-02,  1.47841021e-01]]],\n\n\n       [[[ 1.13745525e-01, -8.69474858e-02,  8.37618485e-02],\n         [ 7.71139339e-02, -5.49041964e-02,  1.01853117e-01],\n         [ 1.08937405e-01,  5.85335447e-03, -6.39039697e-03],\n         ...,\n         [-9.06210300e-03, -5.80512919e-02,  5.98527864e-02],\n         [ 1.89240035e-02,  2.48043481e-02, -3.25884037e-02],\n         [-3.19814943e-02, -6.60498021e-03, -2.48414576e-02]],\n\n        [[-2.57393066e-02, -1.26355037e-01,  5.89941442e-02],\n         [ 1.42653495e-01, -6.69043185e-03,  6.87062219e-02],\n         [ 6.06159940e-02,  7.94254988e-02,  1.73898544e-02],\n         ...,\n         [-2.11379547e-02, -3.42820026e-02, -3.93219031e-02],\n         [-3.82683836e-02,  3.53488289e-02, -6.21722788e-02],\n         [-3.35703678e-02,  1.70730352e-02, -8.12408552e-02]],\n\n        [[ 6.46114722e-02, -1.42887250e-01,  1.38218090e-01],\n         [ 1.02903880e-02, -1.17123239e-01,  1.36382297e-01],\n         [-3.82441655e-02,  3.06384526e-02, -2.49877144e-02],\n         ...,\n         [-1.27674475e-01, -9.14674327e-02,  9.03582647e-02],\n         [-1.23294801e-01,  6.43126890e-02, -4.51706424e-02],\n         [-1.25682503e-01, -2.70616682e-03,  7.90578127e-03]],\n\n        ...,\n\n        [[-2.59251278e-02, -2.34795570e-01,  4.12351638e-02],\n         [ 1.18275017e-01, -3.18749025e-02,  2.25962587e-02],\n         [ 1.47698283e-01,  2.85415445e-02,  1.13272190e-01],\n         ...,\n         [-5.51097728e-02, -8.73290300e-02, -1.86994642e-01],\n         [ 5.15471771e-02,  4.18602042e-02,  5.63824363e-02],\n         [-7.62954168e-03, -2.43163910e-02, -9.95148346e-02]],\n\n        [[ 7.46444520e-03, -4.39421497e-02,  1.14277624e-01],\n         [ 5.74956574e-02, -7.41633624e-02,  1.13105044e-01],\n         [-1.10896140e-01,  1.18825383e-01, -6.36265730e-04],\n         ...,\n         [ 6.00191616e-02, -5.03241085e-03,  7.79773518e-02],\n         [-1.32469088e-01,  4.61681932e-02, -8.41935277e-02],\n         [ 5.68566564e-03,  1.07189745e-01,  1.38347531e-02]],\n\n        [[-2.19346974e-02, -5.79145476e-02,  1.66028086e-03],\n         [ 1.21897543e-02,  7.48943165e-02,  7.36828446e-02],\n         [ 8.80521908e-02,  1.59974918e-01,  6.10561073e-02],\n         ...,\n         [-1.01057507e-01,  6.42772168e-02,  3.04354765e-02],\n         [ 1.65236220e-02,  2.21478328e-01,  2.85117030e-02],\n         [-1.76803786e-02,  6.91779479e-02,  5.16476408e-02]]],\n\n\n       [[[ 1.10497959e-01, -8.64869654e-02,  8.68512690e-02],\n         [ 7.40571767e-02, -4.77747954e-02,  1.10834472e-01],\n         [ 1.15685835e-01,  5.48869744e-03, -6.61586598e-03],\n         ...,\n         [-1.34805599e-02, -6.10397272e-02,  6.00422435e-02],\n         [ 2.43736189e-02,  2.59935968e-02, -3.48308906e-02],\n         [-3.25347707e-02, -7.01530185e-03, -2.25905497e-02]],\n\n        [[-3.04050855e-02, -1.29632309e-01,  6.06596507e-02],\n         [ 1.37808651e-01, -2.41656112e-03,  7.69156665e-02],\n         [ 4.25382182e-02,  6.63907900e-02,  2.88276169e-02],\n         ...,\n         [-2.12748479e-02, -3.95761840e-02, -4.19873856e-02],\n         [-3.14702280e-02,  3.47110629e-02, -6.46593347e-02],\n         [-3.34843509e-02,  1.57412123e-02, -7.95640275e-02]],\n\n        [[ 6.60249442e-02, -1.38223469e-01,  1.47188917e-01],\n         [ 2.65456759e-03, -9.94316414e-02,  1.55461773e-01],\n         [-1.96714457e-02,  3.53120565e-02, -2.36176234e-02],\n         ...,\n         [-1.37881041e-01, -9.87758115e-02,  9.50028077e-02],\n         [-1.17138840e-01,  7.26415962e-02, -4.68891039e-02],\n         [-1.26803830e-01, -3.88489524e-03,  1.30035160e-02]],\n\n        ...,\n\n        [[-5.64410612e-02, -3.53077263e-01,  6.98336633e-03],\n         [ 1.51352853e-01, -1.03410505e-01, -3.99436206e-02],\n         [ 2.27595940e-01, -6.14587776e-02,  1.52471751e-01],\n         ...,\n         [-8.92279483e-03, -2.60124415e-01, -2.07312301e-01],\n         [ 4.12101066e-03, -1.86467275e-01,  1.15846723e-01],\n         [ 1.32875992e-02, -1.12550467e-01, -1.14691816e-01]],\n\n        [[ 2.08015274e-02, -6.81338692e-03,  9.93391871e-02],\n         [ 9.45036411e-02, -1.24745630e-01,  9.44243670e-02],\n         [-1.77189827e-01,  1.99296311e-01, -8.65853056e-02],\n         ...,\n         [ 3.37118544e-02,  3.57520506e-02,  2.32954681e-01],\n         [-1.49183825e-01,  1.45291194e-01, -4.03777547e-02],\n         [-3.08276452e-02,  1.45036414e-01,  1.54369622e-01]],\n\n        [[-8.99775699e-03, -2.90382188e-02, -4.95657735e-02],\n         [ 1.45546044e-04,  1.60738811e-01,  9.58222076e-02],\n         [ 1.88467950e-01,  2.70168066e-01,  5.38377315e-02],\n         ...,\n         [ 7.60310749e-03,  1.39012754e-01,  4.81254011e-02],\n         [ 6.14272058e-02,  2.80610919e-01, -3.32607888e-02],\n         [ 6.68383762e-02,  9.66669172e-02,  6.30585477e-02]]]],\n      dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# 잠재 공간에서 랜덤한 포인트를 샘플링합니다\nrandom_latent_vectors = np.random.normal(size=(10, latent_dim))\n\n# 가짜 이미지로 디코딩합니다\ngenerated_images = generator.predict(random_latent_vectors)\n\nfor i in range(generated_images.shape[0]):\n    img = image.array_to_img(generated_images[i] * 255., scale=False)\n    plt.figure()\n    plt.imshow(img)\n    \nplt.show()\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ngan_img_dir = \"./gan_images\"\n\nfor i in os.listdir(gan_img_dir):\n  # load the image\n    img = Image.open(os.path.join(gan_img_dir, i))\n    img = asarray(img)\n    img = image.array_to_img(img[i] * 255., scale=False)\n    plt.figure()\n    plt.imshow(img)\n    \nplt.show()","execution_count":19,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'JpegImageFile' object has no attribute 'array_to_img'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-97a331054b74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan_img_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'JpegImageFile' object has no attribute 'array_to_img'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 잠재 공간에서 랜덤한 포인트를 샘플링합니다\nrandom_latent_vectors = np.random.normal(size=(10, latent_dim))\n\n# 가짜 이미지로 디코딩합니다\ngenerated_images = generator.predict(random_latent_vectors)\n\nfor i in range(generated_images.shape[0]):\n    img = image.array_to_img(generated_images[i] * 255., scale=False)\n    plt.figure()\n    plt.imshow(img)\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generated_img = []\n\n\ngan_img_dir = \"./gan_images\"\n\nfor i in os.listdir(gan_img_dir):\n  # load the image\n  image = Image.open(os.path.join(gan_img_dir, i))\n  # convert image to numpy array\n  data = asarray(image)\n  generated_img.append(data)\n\ngenerated_img= asarray(generated_img)\ngenerated_img = generated_img/255.    #정규화\ngenerated_img","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"array([[[[0.95294118, 0.94901961, 0.94901961],\n         [0.24313725, 0.96078431, 0.95686275],\n         [0.95686275, 0.24313725, 0.89803922],\n         ...,\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.50588235],\n         [0.50196078, 0.        , 0.23529412]],\n\n        [[0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.50588235],\n         ...,\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.50588235],\n         [0.50196078, 0.        , 0.23529412]],\n\n        [[0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         ...,\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ]],\n\n        ...,\n\n        [[0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         ...,\n         [0.        , 0.50588235, 0.50196078],\n         [0.50196078, 0.23137255, 0.        ],\n         [0.        , 0.        , 0.        ]],\n\n        [[0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         ...,\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ]],\n\n        [[0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         ...,\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ]]],\n\n\n       [[[0.50588235, 0.50196078, 0.50196078],\n         [0.23137255, 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         ...,\n         [0.        , 0.63137255, 0.62745098],\n         [0.62745098, 0.23529412, 0.        ],\n         [0.        , 0.        , 0.        ]],\n\n        [[0.        , 0.        , 0.        ],\n         [0.        , 0.50588235, 0.50196078],\n         [0.50196078, 0.23529412, 0.        ],\n         ...,\n         [0.        , 0.50588235, 0.50196078],\n         [0.50196078, 0.23137255, 0.        ],\n         [0.        , 0.        , 0.        ]],\n\n        [[0.        , 0.        , 0.        ],\n         [0.        , 0.50588235, 0.50196078],\n         [0.50196078, 0.23137255, 0.        ],\n         ...,\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ]],\n\n        ...,\n\n        [[0.95686275, 0.95294118, 0.45098039],\n         [0.24705882, 0.85098039, 0.84705882],\n         [0.34509804, 0.24705882, 0.6745098 ],\n         ...,\n         [0.        , 0.50588235, 0.50196078],\n         [0.50196078, 0.23137255, 0.50588235],\n         [0.50196078, 0.50196078, 0.23529412]],\n\n        [[0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         ...,\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ]],\n\n        [[0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         ...,\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ]]],\n\n\n       [[[0.55686275, 0.55294118, 0.43529412],\n         [0.24313725, 0.74117647, 0.41960784],\n         [0.18823529, 0.74509804, 0.11764706],\n         ...,\n         [0.25098039, 0.37647059, 0.17647059],\n         [0.54901961, 0.74509804, 0.70196078],\n         [0.30196078, 0.45490196, 0.24705882]],\n\n        [[0.05490196, 0.00392157, 0.16862745],\n         [0.24705882, 0.76078431, 0.73333333],\n         [0.2627451 , 0.74901961, 0.76470588],\n         ...,\n         [0.24705882, 0.10980392, 0.2       ],\n         [0.01960784, 0.74901961, 0.15294118],\n         [0.00784314, 0.45490196, 0.74509804]],\n\n        [[0.74117647, 0.31372549, 0.31372549],\n         [0.74509804, 0.74901961, 0.34901961],\n         [0.45882353, 0.74901961, 0.76078431],\n         ...,\n         [0.74117647, 0.63529412, 0.94117647],\n         [0.34509804, 0.74901961, 0.08627451],\n         [0.50980392, 0.43137255, 0.24313725]],\n\n        ...,\n\n        [[0.03921569, 0.43137255, 0.55686275],\n         [0.24705882, 0.58823529, 0.75686275],\n         [0.3372549 , 0.24313725, 0.67058824],\n         ...,\n         [0.25098039, 0.60784314, 0.81960784],\n         [0.24705882, 0.74901961, 0.1372549 ],\n         [0.99607843, 0.01960784, 0.23921569]],\n\n        [[0.68627451, 0.88235294, 0.03137255],\n         [0.24705882, 0.9372549 , 0.64705882],\n         [0.96078431, 0.74509804, 0.71764706],\n         ...,\n         [0.25098039, 0.95294118, 0.12941176],\n         [0.50588235, 0.74901961, 0.58823529],\n         [0.37647059, 0.90196078, 0.23921569]],\n\n        [[0.95294118, 0.73333333, 0.83529412],\n         [0.24313725, 0.09019608, 0.68627451],\n         [0.58431373, 0.24313725, 0.21960784],\n         ...,\n         [0.24705882, 0.80392157, 0.58039216],\n         [0.59215686, 0.74901961, 0.21960784],\n         [0.64705882, 0.33333333, 0.74509804]]],\n\n\n       ...,\n\n\n       [[[0.06666667, 0.16078431, 0.10196078],\n         [0.24313725, 0.45490196, 0.99607843],\n         [0.83529412, 0.74117647, 0.8       ],\n         ...,\n         [0.74509804, 0.74509804, 0.88235294],\n         [0.13333333, 0.24705882, 0.96078431],\n         [0.15294118, 0.2       , 0.24705882]],\n\n        [[0.51372549, 0.76862745, 0.86666667],\n         [0.74509804, 0.47843137, 0.1372549 ],\n         [0.04313725, 0.24705882, 0.6627451 ],\n         ...,\n         [0.74509804, 0.53333333, 0.60784314],\n         [0.09411765, 0.24705882, 0.70196078],\n         [0.5254902 , 0.16862745, 0.24705882]],\n\n        [[0.51764706, 0.70588235, 0.51764706],\n         [0.74509804, 0.92156863, 0.4627451 ],\n         [0.12156863, 0.24705882, 0.48235294],\n         ...,\n         [0.74509804, 0.74117647, 0.56862745],\n         [0.16862745, 0.24705882, 0.33333333],\n         [0.8745098 , 0.04313725, 0.24705882]],\n\n        ...,\n\n        [[0.34901961, 0.74901961, 0.76470588],\n         [0.24313725, 0.39215686, 0.55294118],\n         [0.63137255, 0.24705882, 0.98823529],\n         ...,\n         [0.24705882, 0.20392157, 0.84705882],\n         [0.6745098 , 0.24705882, 0.35294118],\n         [0.        , 0.49803922, 0.24705882]],\n\n        [[0.38431373, 0.92941176, 0.90980392],\n         [0.23921569, 0.25490196, 0.07843137],\n         [0.49411765, 0.24705882, 0.13333333],\n         ...,\n         [0.24313725, 0.93333333, 0.98823529],\n         [0.39607843, 0.24705882, 0.68235294],\n         [0.9372549 , 0.71372549, 0.24705882]],\n\n        [[0.24313725, 0.47058824, 0.57647059],\n         [0.24313725, 0.87843137, 0.64313725],\n         [0.58039216, 0.24705882, 0.79607843],\n         ...,\n         [0.23137255, 0.28627451, 0.54901961],\n         [0.3372549 , 0.74509804, 0.52941176],\n         [0.3254902 , 0.50588235, 0.24705882]]],\n\n\n       [[[0.9372549 , 0.29803922, 0.98431373],\n         [0.24705882, 0.34117647, 0.81176471],\n         [0.22352941, 0.75294118, 0.38431373],\n         ...,\n         [0.24313725, 0.20784314, 0.40784314],\n         [0.60784314, 0.75294118, 0.06666667],\n         [0.69411765, 0.53333333, 0.24705882]],\n\n        [[0.00784314, 0.55686275, 0.83921569],\n         [0.24705882, 0.43921569, 0.70588235],\n         [0.68235294, 0.75294118, 0.8627451 ],\n         ...,\n         [0.74117647, 0.07058824, 0.75294118],\n         [0.56078431, 0.75294118, 0.35686275],\n         [0.05882353, 0.81568627, 0.24705882]],\n\n        [[0.43921569, 0.79607843, 0.89411765],\n         [0.24705882, 0.41176471, 0.50980392],\n         [0.70588235, 0.75294118, 0.48235294],\n         ...,\n         [0.24705882, 0.41568627, 1.        ],\n         [0.49803922, 0.75294118, 0.97254902],\n         [0.32941176, 0.56470588, 0.24705882]],\n\n        ...,\n\n        [[0.1372549 , 0.24705882, 0.1254902 ],\n         [0.25490196, 0.71764706, 0.94901961],\n         [0.30980392, 0.75686275, 0.7372549 ],\n         ...,\n         [0.25098039, 0.03921569, 0.18431373],\n         [0.05098039, 0.75686275, 0.40784314],\n         [0.51372549, 0.80392157, 0.25098039]],\n\n        [[0.50980392, 0.73333333, 0.18823529],\n         [0.25490196, 0.52156863, 0.87843137],\n         [0.23137255, 0.75686275, 0.25882353],\n         ...,\n         [0.25098039, 0.89411765, 0.65882353],\n         [0.02352941, 0.75686275, 0.71764706],\n         [0.51764706, 0.65490196, 0.25098039]],\n\n        [[0.92156863, 0.2       , 0.08627451],\n         [0.25490196, 0.09803922, 0.13333333],\n         [0.14509804, 0.75686275, 0.63137255],\n         ...,\n         [0.25098039, 0.83137255, 0.78431373],\n         [0.20392157, 0.75294118, 0.24313725],\n         [0.7254902 , 0.02745098, 0.25098039]]],\n\n\n       [[[0.95294118, 0.94901961, 0.94901961],\n         [0.24313725, 0.96078431, 0.95686275],\n         [0.95686275, 0.24313725, 0.89803922],\n         ...,\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.50588235],\n         [0.50196078, 0.        , 0.23529412]],\n\n        [[0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.50588235],\n         ...,\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.50588235],\n         [0.50196078, 0.        , 0.23529412]],\n\n        [[0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         ...,\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ]],\n\n        ...,\n\n        [[0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         ...,\n         [0.        , 0.50588235, 0.50196078],\n         [0.50196078, 0.23137255, 0.        ],\n         [0.        , 0.        , 0.        ]],\n\n        [[0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         ...,\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ]],\n\n        [[0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         ...,\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ]]]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"generated_img[0]","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"array([[[0.95294118, 0.94901961, 0.94901961],\n        [0.24313725, 0.96078431, 0.95686275],\n        [0.95686275, 0.24313725, 0.89803922],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.50588235],\n        [0.50196078, 0.        , 0.23529412]],\n\n       [[0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.50588235],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.50588235],\n        [0.50196078, 0.        , 0.23529412]],\n\n       [[0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]],\n\n       ...,\n\n       [[0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.        , 0.50588235, 0.50196078],\n        [0.50196078, 0.23137255, 0.        ],\n        [0.        , 0.        , 0.        ]],\n\n       [[0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]],\n\n       [[0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train[0]","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"array([[[0.00036909, 0.0005075 , 0.00046136],\n        [0.00035371, 0.00049212, 0.00044598],\n        [0.00035371, 0.00049212, 0.00044598],\n        ...,\n        [0.00035371, 0.00052288, 0.00046136],\n        [0.00035371, 0.00052288, 0.00046136],\n        [0.00033833, 0.0005075 , 0.00044598]],\n\n       [[0.00035371, 0.00049212, 0.00044598],\n        [0.00035371, 0.00052288, 0.00046136],\n        [0.00035371, 0.00052288, 0.00046136],\n        ...,\n        [0.00035371, 0.00052288, 0.00046136],\n        [0.00035371, 0.00052288, 0.00046136],\n        [0.00035371, 0.00052288, 0.00046136]],\n\n       [[0.00035371, 0.00052288, 0.00046136],\n        [0.00035371, 0.00052288, 0.00046136],\n        [0.00035371, 0.00052288, 0.00046136],\n        ...,\n        [0.00035371, 0.00052288, 0.00046136],\n        [0.00035371, 0.00052288, 0.00046136],\n        [0.00035371, 0.00052288, 0.00046136]],\n\n       ...,\n\n       [[0.00035371, 0.00052288, 0.00046136],\n        [0.00035371, 0.00052288, 0.00046136],\n        [0.00035371, 0.00052288, 0.00046136],\n        ...,\n        [0.00035371, 0.00052288, 0.00046136],\n        [0.00035371, 0.00052288, 0.00046136],\n        [0.00035371, 0.00052288, 0.00046136]],\n\n       [[0.00033833, 0.0005075 , 0.00044598],\n        [0.00035371, 0.00052288, 0.00046136],\n        [0.00035371, 0.00052288, 0.00046136],\n        ...,\n        [0.00035371, 0.00052288, 0.00046136],\n        [0.00035371, 0.00052288, 0.00046136],\n        [0.00035371, 0.00052288, 0.00046136]],\n\n       [[0.00033833, 0.0005075 , 0.00044598],\n        [0.00036909, 0.00053825, 0.00047674],\n        [0.00035371, 0.00052288, 0.00046136],\n        ...,\n        [0.00035371, 0.00052288, 0.00046136],\n        [0.00035371, 0.00052288, 0.00046136],\n        [0.00035371, 0.00052288, 0.00046136]]], dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}